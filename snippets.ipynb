{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfd9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 1\n",
    "\n",
    "# Adds locations and routes to a map using geolocator\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import folium\n",
    "from functools import lru_cache\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Please add your API key for Google Maps Directions API\n",
    "API_KEY = ''\n",
    "\n",
    "# Create a cache for route calculations\n",
    "@lru_cache(maxsize=None)\n",
    "def calculate_route(origin, destination):\n",
    "    url = f'https://maps.googleapis.com/maps/api/directions/json?origin={origin[0]},{origin[1]}&destination={destination[0]},{destination[1]}&mode=walking&key={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "# Add the simulation country here\n",
    "country = 'mali'\n",
    "\n",
    "# Define the file paths\n",
    "locations_csv_file = os.path.join(country, 'locations.csv')\n",
    "output_geojson_file = os.path.join(country, 'routes.geojson')\n",
    "\n",
    "# Read the data from the CSV file and extract the conflict zone and camp locations\n",
    "conflict_zone_locations = []\n",
    "camp_locations = []\n",
    "\n",
    "with open(locations_csv_file, 'r') as file:\n",
    "    lines = file.readlines()[1:]  # Skip the header line\n",
    "    for line in lines:\n",
    "        fields = line.strip().split(',')\n",
    "        location_name = fields[0]\n",
    "        location_coordinates = (float(fields[3]), float(fields[4]))\n",
    "        location_type = fields[5]\n",
    "        if location_type == 'conflict_zone':\n",
    "            conflict_zone_locations.append((location_name, location_coordinates))\n",
    "        elif location_type == 'camp':\n",
    "            camp_locations.append((location_name, location_coordinates))\n",
    "\n",
    "# Process each conflict zone\n",
    "features = []\n",
    "for zone1 in conflict_zone_locations + camp_locations:\n",
    "    zone1_name, zone1_coordinates = zone1\n",
    "\n",
    "    # Calculate routes from the current location to all other conflict zones and camps\n",
    "    routes = []\n",
    "    for zone2 in conflict_zone_locations + camp_locations:\n",
    "        zone2_name, zone2_coordinates = zone2\n",
    "\n",
    "        # Skip if the locations are the same\n",
    "        if zone1_name == zone2_name:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Calculate the route or retrieve from cache\n",
    "            data = calculate_route(zone1_coordinates, zone2_coordinates)\n",
    "\n",
    "            # Check if the route is found\n",
    "            if data['status'] == 'OK':\n",
    "                # Extract the route coordinates\n",
    "                coordinates = []\n",
    "                for step in data['routes'][0]['legs'][0]['steps']:\n",
    "                    start_location = step['start_location']\n",
    "                    end_location = step['end_location']\n",
    "                    coordinates.append((start_location['lat'], start_location['lng']))\n",
    "                    coordinates.append((end_location['lat'], end_location['lng']))\n",
    "\n",
    "                # Create a LineString object from the route coordinates\n",
    "                route_line = LineString(coordinates)\n",
    "\n",
    "                # Simplify the LineString by reducing the number of points\n",
    "                tolerance = 0.001  # Adjust the tolorance \"up\" for more and \"down\" for fewrer coordinates \n",
    "                simplified_route = route_line.simplify(tolerance)\n",
    "\n",
    "                # Extract the simplified coordinates from the LineString object\n",
    "                simplified_coordinates = list(simplified_route.coords)\n",
    "\n",
    "                routes.append({\n",
    "                    'name': zone2_name,\n",
    "                    'coordinates': simplified_coordinates\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                print(f\"No route found between {zone1_name} and {zone2_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "\n",
    "    # Add the routes as features to the GeoJSON\n",
    "    if routes:\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"MultiLineString\",\n",
    "                \"coordinates\": [route['coordinates'] for route in routes]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"start\": {\n",
    "                    \"name\": zone1_name,\n",
    "                    \"coordinates\": simplified_coordinates\n",
    "                },\n",
    "                \"routes\": routes\n",
    "            }\n",
    "        }\n",
    "        features.append(feature)\n",
    "\n",
    "# Create the GeoJSON object\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "\n",
    "# Printouts for total number of coordinates in GeoJson file and between routes \n",
    "total_coordinates = 0\n",
    "\n",
    "# Iterate over the features and calculate the total number of coordinates\n",
    "for feature in geojson['features']:\n",
    "    coordinates = feature['geometry']['coordinates'][0]\n",
    "    total_coordinates += len(coordinates)\n",
    "\n",
    "print(\"Total number of coordinates in the GeoJSON file (excluding start/end):\", total_coordinates)\n",
    "\n",
    "# Iterate over the features and count the number of coordinates per route\n",
    "for feature in geojson['features']:\n",
    "    coordinates = feature['geometry']['coordinates'][0]\n",
    "    num_coordinates = len(coordinates)\n",
    "    print(f\"Route: {feature['properties']['start']['name']} to {feature['properties']['routes'][0]['name']} with {num_coordinates} coordinates.\")\n",
    "\n",
    "\n",
    "# Save the GeoJSON to a file\n",
    "with open(output_geojson_file, \"w\") as file:\n",
    "    json.dump(geojson, file)\n",
    "\n",
    "print(\"GeoJSON file saved successfully.\")\n",
    "\n",
    "# Read the GeoJSON file\n",
    "with open(output_geojson_file) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Calculate the center location based on all coordinates\n",
    "all_coordinates = [coord for _, coord in conflict_zone_locations + camp_locations]\n",
    "m = folium.Map(location=all_coordinates[0], zoom_start=6)\n",
    "\n",
    "# Iterate over the features and add them as PolyLine to the map\n",
    "for feature in data['features']:\n",
    "    coordinates = feature['geometry']['coordinates'][0]\n",
    "    folium.PolyLine(locations=coordinates, color='blue').add_to(m)\n",
    "\n",
    "# Add conflict zones as green circles\n",
    "for zone in conflict_zone_locations:\n",
    "    zone_name, zone_coordinates = zone\n",
    "    folium.CircleMarker(location=zone_coordinates, \n",
    "                        radius=6, color='red', \n",
    "                        fill=True, fill_color='red').add_to(m)\n",
    "    folium.Marker(\n",
    "        location=zone_coordinates, \n",
    "        popup=zone_name,\n",
    "        icon=folium.DivIcon(icon_size=(1,1))\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add camps as red circles\n",
    "for camp in camp_locations:\n",
    "    camp_name, camp_coordinates = camp\n",
    "    folium.CircleMarker(location=camp_coordinates, \n",
    "                        radius=6, color='green', \n",
    "                        fill=True, fill_color='green').add_to(m)\n",
    "    folium.Marker(\n",
    "        location=camp_coordinates,\n",
    "        tooltip=camp_name,\n",
    "        icon=folium.DivIcon(icon_size=(1,1))\n",
    "    ).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 2\n",
    "\n",
    "# Snippet 2 is a faster version of Snippet 1 \n",
    "\n",
    "import requests\n",
    "import json\n",
    "import folium\n",
    "from functools import lru_cache\n",
    "from shapely.geometry import LineString\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# API key for Google Maps Directions API\n",
    "API_KEY = ''\n",
    "\n",
    "# Create a cache for route calculations\n",
    "@lru_cache(maxsize=None)\n",
    "def calculate_route(origin, destination):\n",
    "    url = f'https://maps.googleapis.com/maps/api/directions/json?origin={origin[0]},{origin[1]}&destination={destination[0]},{destination[1]}&mode=walking&key={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "# Define a function to calculate the route for a given pair of locations\n",
    "def calculate_route_for_pair(zone1, zone2):\n",
    "    zone1_name, zone1_coordinates = zone1\n",
    "    zone2_name, zone2_coordinates = zone2\n",
    "\n",
    "    # Skip if the locations are the same\n",
    "    if zone1_name == zone2_name:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Calculate the route or retrieve from cache\n",
    "        data = calculate_route(zone1_coordinates, zone2_coordinates)\n",
    "\n",
    "        # Check if the route is found\n",
    "        if data['status'] == 'OK':\n",
    "            # Extract the route coordinates\n",
    "            coordinates = []\n",
    "            for step in data['routes'][0]['legs'][0]['steps']:\n",
    "                start_location = step['start_location']\n",
    "                end_location = step['end_location']\n",
    "                coordinates.append((start_location['lat'], start_location['lng']))\n",
    "                coordinates.append((end_location['lat'], end_location['lng']))\n",
    "\n",
    "            # Create a LineString object from the route coordinates\n",
    "            route_line = LineString(coordinates)\n",
    "\n",
    "            # Simplify the LineString by reducing the number of points\n",
    "            tolerance = 0.0001  # Adjust the tolerance \"up\" for more and \"down\" for fewer coordinates\n",
    "            simplified_route = route_line.simplify(tolerance)\n",
    "\n",
    "            # Extract the simplified coordinates from the LineString object\n",
    "            simplified_coordinates = list(simplified_route.coords)\n",
    "\n",
    "            return {\n",
    "                'name': zone2_name,\n",
    "                'coordinates': simplified_coordinates\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            print(f\"No route found between {zone1_name} and {zone2_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# Add the simulation country here\n",
    "country = 'mali'\n",
    "\n",
    "# Define the file paths\n",
    "locations_csv_file = os.path.join(country, 'locations.csv')\n",
    "output_geojson_file = os.path.join(country, 'routes.geojson')\n",
    "\n",
    "# Read the data from the CSV file and extract the conflict zone and camp locations\n",
    "conflict_zone_locations = []\n",
    "camp_locations = []\n",
    "\n",
    "with open(locations_csv_file, 'r') as file:\n",
    "    lines = file.readlines()[1:]\n",
    "    for line in lines:\n",
    "        fields = line.strip().split(',')\n",
    "        location_name = fields[0]\n",
    "        location_coordinates = (float(fields[3]), float(fields[4]))\n",
    "        location_type = fields[5]\n",
    "        if location_type == 'conflict_zone':\n",
    "            conflict_zone_locations.append((location_name, location_coordinates))\n",
    "        elif location_type == 'camp':\n",
    "            camp_locations.append((location_name, location_coordinates))\n",
    "\n",
    "# Process each conflict zone\n",
    "features = []\n",
    "num_locations = len(conflict_zone_locations + camp_locations)\n",
    "num_pairs = num_locations * (num_locations - 1)\n",
    "\n",
    "# Create a list of location pairs for parallel processing\n",
    "location_pairs = []\n",
    "for zone1 in conflict_zone_locations + camp_locations:\n",
    "    for zone2 in conflict_zone_locations + camp_locations:\n",
    "        location_pairs.append((zone1, zone2))\n",
    "\n",
    "\n",
    "# Define a function to calculate routes for a batch of location pairs\n",
    "def calculate_routes_batch(location_pairs):\n",
    "    routes = []\n",
    "    for zone1, zone2 in location_pairs:\n",
    "        route = calculate_route_for_pair(zone1, zone2)\n",
    "        if route:\n",
    "            routes.append(route)\n",
    "    return routes\n",
    "\n",
    "\n",
    "# Split the location pairs into chunks for parallel processing\n",
    "num_processes = cpu_count()\n",
    "chunk_size = num_pairs // num_processes\n",
    "chunks = [location_pairs[i:i+chunk_size] for i in range(0, num_pairs, chunk_size)]\n",
    "\n",
    "# Create a multiprocessing Pool and map the chunks to worker processes\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    results = pool.map(calculate_routes_batch, chunks)\n",
    "\n",
    "# Flatten the results from all processes\n",
    "routes = [route for result in results for route in result if route]\n",
    "\n",
    "# Add the routes as features to the GeoJSON\n",
    "for zone1 in conflict_zone_locations + camp_locations:\n",
    "    zone1_name, zone1_coordinates = zone1\n",
    "    zone_routes = [route for route in routes if route['name'] == zone1_name]\n",
    "    if zone_routes:\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"MultiLineString\",\n",
    "                \"coordinates\": [route['coordinates'] for route in zone_routes]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"start\": {\n",
    "                    \"name\": zone1_name,\n",
    "                    \"coordinates\": zone1_coordinates\n",
    "                },\n",
    "                \"routes\": zone_routes\n",
    "            }\n",
    "        }\n",
    "        features.append(feature)\n",
    "\n",
    "# Create the GeoJSON object\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "# Save the GeoJSON to a file\n",
    "with open(output_geojson_file, \"w\") as file:\n",
    "    json.dump(geojson, file)\n",
    "\n",
    "print(\"GeoJSON file saved successfully.\")\n",
    "\n",
    "# Read the GeoJSON file\n",
    "with open(output_geojson_file) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Calculate the center location based on all coordinates\n",
    "all_coordinates = [coord for _, coord in conflict_zone_locations + camp_locations]\n",
    "m = folium.Map(location=all_coordinates[0], zoom_start=6)\n",
    "\n",
    "# Iterate over the features and add them as PolyLine to the map\n",
    "for feature in data['features']:\n",
    "    coordinates = feature['geometry']['coordinates'][0]\n",
    "    folium.PolyLine(locations=coordinates, color='blue').add_to(m)\n",
    "\n",
    "# Add conflict zones as green circles\n",
    "for zone in conflict_zone_locations:\n",
    "    zone_name, zone_coordinates = zone\n",
    "    folium.CircleMarker(location=zone_coordinates, \n",
    "                        radius=6, color='red', \n",
    "                        fill=True, fill_color='red').add_to(m)\n",
    "    folium.Marker(\n",
    "        location=zone_coordinates, \n",
    "        popup=zone_name,\n",
    "        icon=folium.DivIcon(icon_size=(1,1))\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add camps as red circles\n",
    "for camp in camp_locations:\n",
    "    camp_name, camp_coordinates = camp\n",
    "    folium.CircleMarker(location=camp_coordinates, \n",
    "                        radius=6, color='green', \n",
    "                        fill=True, fill_color='green').add_to(m)\n",
    "    folium.Marker(\n",
    "        location=camp_coordinates,\n",
    "        tooltip=camp_name,\n",
    "        icon=folium.DivIcon(icon_size=(1,1))\n",
    "    ).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 4\n",
    "\n",
    "# Creates conflict scenario from scratch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "# Read conflict zones from conflicts.csv\n",
    "def read_conflict_zones(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    conflict_zones = df.columns[1:].tolist()\n",
    "    return conflict_zones\n",
    "\n",
    "# Custom function to generate all zeros csv file\n",
    "def generate_conflict_zones_csv(filename, conflict_zones, period):\n",
    "    data = {'#Days': list(range(period))}\n",
    "    data.update({zone: [0] * period for zone in conflict_zones})\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "# Generating random numbers\n",
    "def custom_distribution1(x):\n",
    "    max_value = 10\n",
    "    variation_factor = 0.1\n",
    "    \n",
    "    # Generate random numbers with the specified maximum value and variation factor\n",
    "    y = np.random.uniform(0, max_value, len(x))\n",
    "\n",
    "    # Add random fluctuations to the random numbers\n",
    "    y += np.random.normal(0, variation_factor, len(x))\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 2\n",
    "def custom_distribution2(x):\n",
    "    period = 365  # Length of one complete period (in days)\n",
    "    max_value = 10  # Maximum value for conflict intensity\n",
    "    variation_factor = 0.5  # Adjust the variation factor as desired\n",
    "\n",
    "    # Compute the phase angle based on the day of the year\n",
    "    phase_angle = (x % period) / period * 2 * np.pi\n",
    "\n",
    "    # Use a sine function to model the seasonal variation\n",
    "    y = max_value * np.sin(phase_angle)\n",
    "\n",
    "    # Add random noise with the specified variation factor\n",
    "    y += np.random.normal(0, variation_factor, len(x))\n",
    "    y = np.abs(y)  # Take the absolute value of y\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "# CSV Headers\n",
    "conflict_zones = ['Gao', 'Segou', 'Tombouctou', 'Douentza', 'Kayes', 'Sikasso', 'Koulikoro', 'Menaka', 'Kidal', 'Bamako']\n",
    "\n",
    "# Specify the simulation period\n",
    "period = 732\n",
    "\n",
    "# Specify simulation country\n",
    "country = 'mali'\n",
    "\n",
    "# Create the path to input file\n",
    "input_file = os.path.join(country, 'conflicts.csv')\n",
    "\n",
    "if not os.path.isfile(input_file):\n",
    "    print(\"File does not exist!\")\n",
    "\n",
    "# Call the function to generate all zeros csv file\n",
    "generate_conflict_zones_csv('modified-conflicts.csv', conflict_zones, period)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"modified-conflicts.csv\")\n",
    "\n",
    "# Generate x-axis values from 0 to 731\n",
    "start_date = date(2022, 9, 1)\n",
    "current_date = date(2023, 5, 31)\n",
    "days_passed = (current_date - start_date).days\n",
    "\n",
    "# Generate x-axis values using custom_distribution1 and custom_distribution2\n",
    "x1 = np.linspace(0, days_passed, num=days_passed).astype(int)\n",
    "x2 = np.linspace(days_passed, period, num=period - days_passed).astype(int)\n",
    "\n",
    "# Generate y-axis values using custom_distribution1 and custom_distribution2\n",
    "y1 = custom_distribution1(x1)\n",
    "y2 = custom_distribution2(x2)\n",
    "\n",
    "# Combine the generated data\n",
    "x = np.concatenate((x1, x2))\n",
    "y = np.concatenate((y1, y2))\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# Plot graph\n",
    "ax1.plot(x, y)\n",
    "ax1.set_title('Conflict Distribution')\n",
    "ax1.set_xlabel('Days')\n",
    "ax1.set_ylabel('Conflict Zones')\n",
    "\n",
    "# Convert y values to integers\n",
    "y = [int(val) for val in y]\n",
    "\n",
    "modified_rows = []\n",
    "y_index = 0\n",
    "for _, row in df.iterrows():\n",
    "    row = row.values\n",
    "    if y_index >= len(y):\n",
    "        break\n",
    "\n",
    "    number = y[y_index]\n",
    "    y_index += 1\n",
    "    assigned_count = 0\n",
    "    for i in range(1, len(row)):\n",
    "        if assigned_count < number:\n",
    "            row[i] = 1\n",
    "            assigned_count += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    modified_rows.append(row)\n",
    "\n",
    "# Create modified DataFrame\n",
    "modified_df = pd.DataFrame(modified_rows, columns=df.columns)\n",
    "\n",
    "# Compute the sum of each row (excluding the '#Days' column)\n",
    "sum_values = modified_df.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Set the maximum value for the y-axis in Plot 2\n",
    "max_value = max(max(y), max(sum_values))\n",
    "ax2.set_ylim(0, max_value)\n",
    "\n",
    "# Trim x to match the length of sum_values\n",
    "x = x[:len(sum_values)]\n",
    "\n",
    "# Plot the summed values\n",
    "ax2.plot(x, sum_values)\n",
    "ax2.set_title('Conflict Distribution')\n",
    "ax2.set_xlabel('Days')\n",
    "\n",
    "# Write the modified DataFrame to the CSV file\n",
    "output_file = os.path.join(country, \"modified-conflicts.csv\")\n",
    "\n",
    "# Write the modified DataFrame to the CSV file\n",
    "modified_df.to_csv('modified-conflicts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 5\n",
    "\n",
    "# Adds scenario to the conflicts.csv \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "def read_conflict_zones(filename):\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        conflict_zones = df.columns[1:].tolist()\n",
    "        conflict_zones = [zone for zone in conflict_zones if zone]  # Exclude empty headers\n",
    "        return conflict_zones\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found: \", filename)\n",
    "        return []\n",
    "    \n",
    "    \n",
    "# Custom function to generate all zeros csv file\n",
    "def generate_conflict_zones_csv(filename, conflict_zones, period):\n",
    "    data = {'#Days': list(range(period))}\n",
    "    data.update({zone: [0] * period for zone in conflict_zones})\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "\n",
    "# Custom distribution function 1\n",
    "def custom_distribution1(intensity, x):\n",
    "    peak_day = 100\n",
    "    max_value = intensity\n",
    "    std_deviation = 130\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factor = np.exp(-((x - peak_day) / std_deviation) ** 2)\n",
    "    \n",
    "    # Add random fluctuations to the spreading factor\n",
    "    spreading_factor += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    y = max_value * spreading_factor\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 2\n",
    "def custom_distribution2(intensity, x):\n",
    "    peak_day = 100\n",
    "    max_value = intensity\n",
    "    std_deviation = 100\n",
    "    rise_factor = 1.5\n",
    "    fall_factor = 0.125\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factor_rising = np.exp(-((x - peak_day) / std_deviation) ** 2) ** rise_factor\n",
    "    spreading_factor_falling = np.exp(-((x - peak_day) / (std_deviation * 2)) ** 2) ** fall_factor\n",
    "    \n",
    "    # Add random fluctuations to the spreading factors\n",
    "    spreading_factor_rising += np.random.normal(0, variation_factor, len(x))\n",
    "    spreading_factor_falling += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    y_rising = max_value * spreading_factor_rising\n",
    "    y_falling = max_value * spreading_factor_falling\n",
    "    y = np.where(x < peak_day, y_rising, y_falling)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 3\n",
    "def custom_distribution3(intensity, x):\n",
    "    peak1_day = 150\n",
    "    peak2_day = 650\n",
    "    max_value = intensity\n",
    "    std_deviation1 = 30\n",
    "    std_deviation2 = 50\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factor1 = np.exp(-((x - peak1_day) / std_deviation1) ** 2)\n",
    "    spreading_factor2 = np.exp(-((x - peak2_day) / std_deviation2) ** 2)\n",
    "    \n",
    "    # Add random fluctuations to the spreading factors\n",
    "    spreading_factor1 += np.random.normal(0, variation_factor, len(x))\n",
    "    spreading_factor2 += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    y = max_value * (spreading_factor1 + spreading_factor2)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 4\n",
    "def custom_distribution4(intensity, x):\n",
    "    peak1_day = 150\n",
    "    peak2_day = 650\n",
    "    max_value = intensity\n",
    "    std_deviation1 = 30\n",
    "    std_deviation2 = 50\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factor1 = np.exp(-((x - peak1_day) / std_deviation1) ** 2)\n",
    "    spreading_factor2 = np.exp(-((x - peak2_day) / std_deviation2) ** 2)\n",
    "    \n",
    "    # Add random fluctuations to the spreading factors\n",
    "    spreading_factor1 += np.random.normal(0, variation_factor, len(x))\n",
    "    spreading_factor2 += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    y = max_value * (spreading_factor1 + spreading_factor2)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 5\n",
    "def custom_distribution5(intensity, x):\n",
    "    peaks = [100, 200, 300, 400, 500]  # Adjust the peak days as desired\n",
    "    max_value = intensity\n",
    "    std_deviations = [10, 10, 10, 10, 10]  # Adjust the standard deviations as desired\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factors = []\n",
    "    for peak, std_deviation in zip(peaks, std_deviations):\n",
    "        spreading_factor = np.exp(-((x - peak) / std_deviation) ** 2)\n",
    "        spreading_factor += np.random.normal(0, variation_factor, len(x))\n",
    "        spreading_factors.append(spreading_factor)\n",
    "    \n",
    "    y = max_value * sum(spreading_factors)\n",
    "    return y\n",
    "\n",
    "# Custom distribution function 6\n",
    "def custom_distribution6(intensity, x):\n",
    "    peaks = [150, 300, 450, 600]  # Adjust the peak days as desired\n",
    "    hill_width = 20  # Adjust the width of the hill\n",
    "    max_value = intensity\n",
    "    std_deviations = [10, 20, 30, 40]  # Adjust the standard deviations as desired\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factors = []\n",
    "    for peak, std_deviation in zip(peaks, std_deviations):\n",
    "        spreading_factor = np.exp(-((x - peak) / std_deviation) ** 2)\n",
    "        \n",
    "        # Create the hill shape by adding a flat plateau around the peak\n",
    "        hill_mask = np.logical_and(x >= peak - hill_width, x <= peak + hill_width)\n",
    "        spreading_factor[hill_mask] = max_value\n",
    "        \n",
    "        spreading_factor += np.random.normal(0, variation_factor, len(x))\n",
    "        spreading_factors.append(spreading_factor)\n",
    "    \n",
    "    y = max_value * sum(spreading_factors)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 7\n",
    "def custom_distribution7(intensity, x):\n",
    "    period = 365  # Length of one complete period (in days)\n",
    "    max_value = intensity  # Maximum value for conflict intensity\n",
    "    variation_factor = 0.5  # Adjust the variation factor as desired\n",
    "    \n",
    "    # Compute the phase angle based on the day of the year\n",
    "    phase_angle = (x % period) / period * 2 * np.pi\n",
    "    \n",
    "    # Use a sine function to model the seasonal variation\n",
    "    y = max_value * np.sin(phase_angle)\n",
    "    \n",
    "    # Add random noise with the specified variation factor\n",
    "    y += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    return y\n",
    "\n",
    "# Specify the simulation country\n",
    "country = 'mali'\n",
    "\n",
    "# Create the path to input file\n",
    "input_file = os.path.join(country, 'conflicts.csv')\n",
    "\n",
    "# Call the function to extract the conflict_zones from the file\n",
    "conflict_zones = read_conflict_zones(input_file)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Specify the simulation period\n",
    "period = 732\n",
    "\n",
    "# Generate x-axis values from 0 to 731\n",
    "start_date = date(2022, 9, 1)\n",
    "current_date = date(2023, 5, 31)\n",
    "days_passed = (current_date - start_date).days\n",
    "\n",
    "# Generate x-axis values using custom_distribution1 and custom_distribution2\n",
    "x1 = np.linspace(0, days_passed, num=days_passed).astype(int)\n",
    "x2 = np.linspace(days_passed, period, num=period - days_passed).astype(int)\n",
    "\n",
    "# Generate y-axis values using conflicts values\n",
    "y1 = df.iloc[:, 1:days_passed + 1].sum(axis=1)[:days_passed]\n",
    "\n",
    "# Use maximum number of conflicts in y1 as intensity\n",
    "intensity = max(y1)\n",
    "\n",
    "# Generate y-axis values using custom_distribution2\n",
    "y2 = custom_distribution7(intensity, x2)\n",
    "\n",
    "# Combine the generated data\n",
    "x = np.concatenate((x1, x2))\n",
    "y = np.concatenate((y1, y2))\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# Plot graph\n",
    "ax1.plot(x, y)\n",
    "ax1.set_title('Conflict Distribution')\n",
    "ax1.set_xlabel('Days')\n",
    "ax1.set_ylabel('Conflict Zones')\n",
    "\n",
    "# Convert y values to integers\n",
    "y = [int(val) for val in y]\n",
    "\n",
    "# Create path to modified CSV file\n",
    "output_file = os.path.join(country, \"modified-conflicts.csv\")\n",
    "\n",
    "# Call the function to generate all zeros csv file\n",
    "generate_conflict_zones_csv(output_file, conflict_zones, period)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_modified = pd.read_csv(output_file)\n",
    "\n",
    "# Update the modified DataFrame with the new y values\n",
    "modified_rows = []\n",
    "y_index = 0\n",
    "for _, row in df_modified.iterrows():\n",
    "    row = row.values\n",
    "    if y_index >= len(y):\n",
    "        break\n",
    "\n",
    "    number = y[y_index]\n",
    "    y_index += 1\n",
    "    assigned_count = 0\n",
    "    for i in range(1, len(row)):\n",
    "        if assigned_count < number:\n",
    "            row[i] = 1\n",
    "            assigned_count += 1\n",
    "        else:\n",
    "            row[i] = 0\n",
    "\n",
    "    modified_rows.append(row)\n",
    "    \n",
    "# Create modified DataFrame\n",
    "modified_df = pd.DataFrame(modified_rows, columns=df.columns)\n",
    "\n",
    "# Compute the sum of each row (excluding the '#Day' column)\n",
    "sum_values = modified_df.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Plot the summed values\n",
    "ax2.plot(x, sum_values)\n",
    "ax2.set_title('Conflict Distribution')\n",
    "ax2.set_xlabel('Days')\n",
    "\n",
    "# Save the modified DataFrame to the output file\n",
    "modified_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34346a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 6\n",
    "\n",
    "# Adds locations and routes to a map using location coordinates\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import folium\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "\n",
    "# Read conflict zones, camps, and towns from the locations.csv file\n",
    "def read_locations(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    conflict_zones = df[df['location_type'] == 'conflict_zone'].copy()\n",
    "    camps = df[df['location_type'] == 'camp'].copy()\n",
    "    towns = df[df['location_type'] == 'town'].copy()\n",
    "\n",
    "    # Remove leading/trailing whitespaces from names\n",
    "    conflict_zones.loc[:, '#name'] = conflict_zones['#name'].str.strip()\n",
    "    camps.loc[:, '#name'] = camps['#name'].str.strip()\n",
    "    towns.loc[:, '#name'] = towns['#name'].str.strip()\n",
    "\n",
    "    return conflict_zones, camps, towns\n",
    "\n",
    "\n",
    "\n",
    "# Specify the simulation country\n",
    "country = 'mali'\n",
    "\n",
    "# Create path to conflicts.csv\n",
    "locations_csv_file = os.path.join(country, 'locations.csv')\n",
    "\n",
    "# Call the function to extract the conflict_zones, camps, and towns from the file\n",
    "conflict_zones, camps, towns = read_locations(locations_csv_file)\n",
    "\n",
    "\n",
    "# Please add your API key for Google Maps Directions API\n",
    "API_KEY = 'AIzaSyAE0Hnd5lee-fhroJ-OfDpt2J0VrJhRr5c'\n",
    "\n",
    "# Create a cache for route calculations\n",
    "route_cache = {}\n",
    "\n",
    "# Function to calculate route using Google Maps Directions API\n",
    "def calculate_route(origin, destination):\n",
    "    cache_key = (origin, destination)\n",
    "    if cache_key in route_cache:\n",
    "        return route_cache[cache_key]\n",
    "\n",
    "    url = f'https://maps.googleapis.com/maps/api/directions/json?origin={origin[0]},{origin[1]}&destination={destination[0]},{destination[1]}&mode=walking&key={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    route_cache[cache_key] = data\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Create a map\n",
    "m = folium.Map(location=[49.0, 31.0], zoom_start=7)\n",
    "\n",
    "num_locations_not_found = 0\n",
    "num_routes_not_found = 0\n",
    "\n",
    "# Find routes between locations\n",
    "features = []\n",
    "\n",
    "# Combine conflict zones, towns, and camps into a single DataFrame\n",
    "all_locations = pd.DataFrame()\n",
    "\n",
    "if not conflict_zones.empty:\n",
    "    all_locations = pd.concat([all_locations, conflict_zones])\n",
    "\n",
    "if not towns.empty:\n",
    "    all_locations = pd.concat([all_locations, towns])\n",
    "\n",
    "if not camps.empty:\n",
    "    all_locations = pd.concat([all_locations, camps])\n",
    "\n",
    "for _, origin in all_locations.iterrows():\n",
    "    origin_name = origin['#name']\n",
    "    origin_lat = origin['latitude']\n",
    "    origin_lon = origin['longitude']\n",
    "    origin_type = origin['location_type']\n",
    "\n",
    "    for _, destination in all_locations.iterrows():\n",
    "        destination_name = destination['#name']\n",
    "        destination_lat = destination['latitude']\n",
    "        destination_lon = destination['longitude']\n",
    "        destination_type = destination['location_type']\n",
    "\n",
    "        # Skip if the origin and destination are the same or have different location types\n",
    "        if origin_name == destination_name or origin_type != destination_type:\n",
    "            continue\n",
    "\n",
    "        # Calculate the route using Google Maps Directions API\n",
    "        data = calculate_route((origin_lat, origin_lon), (destination_lat, destination_lon))\n",
    "\n",
    "        if data['status'] == 'OK':\n",
    "            # Extract the route coordinates\n",
    "            coordinates = []\n",
    "            for step in data['routes'][0]['legs'][0]['steps']:\n",
    "                start_location = step['start_location']\n",
    "                end_location = step['end_location']\n",
    "                coordinates.append((start_location['lat'], start_location['lng']))\n",
    "                coordinates.append((end_location['lat'], end_location['lng']))\n",
    "\n",
    "            # Create a LineString object from the route coordinates\n",
    "            route_line = LineString(coordinates)\n",
    "\n",
    "            # Simplify the LineString by reducing the number of points\n",
    "            tolerance = 0.001  # Adjust the tolerance for the level of simplification\n",
    "            simplified_route = route_line.simplify(tolerance)\n",
    "\n",
    "            # Extract the simplified coordinates from the LineString object\n",
    "            simplified_coordinates = list(simplified_route.coords)\n",
    "\n",
    "            # Add the route as a feature to the GeoJSON\n",
    "            feature = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"LineString\",\n",
    "                    \"coordinates\": simplified_coordinates\n",
    "                },\n",
    "                \"properties\": {\n",
    "                    \"origin\": origin_name,\n",
    "                    \"destination\": destination_name\n",
    "                }\n",
    "            }\n",
    "\n",
    "            features.append(feature)\n",
    "            \n",
    "            # Add the route as a PolyLine to the map\n",
    "            folium.PolyLine(locations=simplified_coordinates, color='gray').add_to(m)\n",
    "        else:\n",
    "            num_routes_not_found += 1\n",
    "            \n",
    "print(\"Number of routes not found:\", num_routes_not_found)\n",
    "\n",
    "# Create the GeoJSON object\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "# Create output file\n",
    "output_file = os.path.join(country, 'routes.geojson')\n",
    "\n",
    "# Save the GeoJSON to a file\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(geojson, file)\n",
    "    \n",
    "    \n",
    "# Add conflict zones as markers\n",
    "if not conflict_zones.empty:\n",
    "    for _, zone in conflict_zones.iterrows():\n",
    "        zone_name = zone['#name'].strip()\n",
    "        zone_lat = zone['latitude']\n",
    "        zone_lon = zone['longitude']\n",
    "        folium.CircleMarker(location=[zone_lat, zone_lon], radius=6, color='red', fill=True, fill_color='red', popup=zone_name).add_to(m)\n",
    "\n",
    "# Add towns as markers\n",
    "if not towns.empty:\n",
    "    for _, town in towns.iterrows():\n",
    "        town_name = town['#name'].strip()\n",
    "        town_lat = town['latitude']\n",
    "        town_lon = town['longitude']\n",
    "        folium.CircleMarker(location=[town_lat, town_lon], radius=6, color='blue', fill=True, fill_color='blue', popup=town_name).add_to(m)\n",
    "\n",
    "# Add camps as markers\n",
    "if not camps.empty:\n",
    "    for _, camp in camps.iterrows():\n",
    "        camp_name = camp['#name'].strip()\n",
    "        camp_lat = camp['latitude']\n",
    "        camp_lon = camp['longitude']\n",
    "        folium.CircleMarker(location=[camp_lat, camp_lon], radius=6, color='green', fill=True, fill_color='green', popup=camp_name).add_to(m)\n",
    "\n",
    "# Display map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281110f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 7\n",
    "\n",
    "# Create population.csv from https://www.citypopulation.de/ site\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "country = 'syria'\n",
    "\n",
    "# Replace 'filename.html' with the path to your HTML file\n",
    "html_file = '{}/{}.html'.format(country, country)\n",
    "\n",
    "# Use pandas' read_html function to read the HTML file and extract all tables\n",
    "tables = pd.read_html(html_file)\n",
    "\n",
    "# We're interested in the first table on the page, so we'll select it\n",
    "table = tables[0]\n",
    "\n",
    "# Select only the desired columns and rename them\n",
    "selected_columns = table[['Name', 'PopulationEstimate (E)2021-07-01']]\n",
    "\n",
    "# Drop rows with missing values in the 'name' and 'Population Estimate (E)2021-07-01' columns\n",
    "selected_columns = selected_columns.dropna(subset=['Name', 'PopulationEstimate (E)2021-07-01'])\n",
    "\n",
    "# Rename columns\n",
    "selected_columns.columns = ['name', 'population']\n",
    "\n",
    "# Save the data to a CSV file\n",
    "output_file = '{}/population.csv'.format(country)\n",
    "selected_columns.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"population.csv file is created. Please inspect the file for non standard characters!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 8\n",
    "\n",
    "# Converts acled.csv and population.csv to locations.csv\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import calendar as cal\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import wikipedia\n",
    "import wbdata\n",
    "\n",
    "def date_format(in_date):\n",
    "    # converting date from textbased to dd-mm-yyyy format\n",
    "    if \"-\" in in_date:\n",
    "        split_date = in_date.split(\"-\")\n",
    "    else:\n",
    "        split_date = in_date.split(\" \")\n",
    "\n",
    "    month_num = month_convert(split_date[1])\n",
    "    if int(split_date[2]) < 50:\n",
    "        year = int(split_date[2]) + 2000\n",
    "    else:\n",
    "        year = int(split_date[2])\n",
    "    out_date = split_date[0] + \"-\" + str(month_num) + \"-\" + str(year)\n",
    "    return out_date\n",
    "\n",
    "def month_convert(month_name):\n",
    "    months = {\n",
    "    \"jan\": \"01\", \"january\": \"01\",\n",
    "    \"feb\": \"02\", \"february\": \"02\",\n",
    "    \"mar\": \"03\", \"march\": \"03\",\n",
    "    \"apr\": \"04\", \"april\": \"04\",\n",
    "    \"may\": \"05\",\n",
    "    \"jun\": \"06\", \"june\": \"06\",\n",
    "    \"jul\": \"07\", \"july\": \"07\",\n",
    "    \"aug\": \"08\", \"august\": \"08\",\n",
    "    \"sep\": \"09\", \"september\": \"09\",\n",
    "    \"oct\": \"10\", \"october\": \"10\",\n",
    "    \"nov\": \"11\", \"november\": \"11\",\n",
    "    \"dec\": \"12\", \"december\": \"12\"\n",
    "    }\n",
    "\n",
    "    # Convert the month name to lowercase and strip leading/trailing whitespace\n",
    "    month_name = month_name.strip().lower()\n",
    "\n",
    "    # Look up the month number in the dictionary\n",
    "    if month_name in months:\n",
    "        month_num = months[month_name]\n",
    "        #print(f\"The month number for {month_name} is {month_num}.\")\n",
    "    else:\n",
    "        print(\"Invalid month name entered.\")\n",
    "\n",
    "    return month_num\n",
    "\n",
    "def between_date(d1, d2):\n",
    "    # Gets difference between two dates in string format \"dd-mm-yyyy\"\n",
    "    d1list = d1.split(\"-\")\n",
    "    d2list = d2.split(\"-\")\n",
    "    date1 = datetime(int(d1list[2]), int(d1list[1]), int(d1list[0]))\n",
    "    date2 = datetime(int(d2list[2]), int(d2list[1]), int(d2list[0]))\n",
    "\n",
    "    return abs((date1 - date2).days)  # Maybe add +1\n",
    "\n",
    "def drop_rows(inputdata, columnname, dropparameter):\n",
    "    removedrows = inputdata.index[\n",
    "        inputdata[columnname] <= dropparameter].tolist()\n",
    "    outputdata = inputdata.drop(removedrows)\n",
    "    return outputdata\n",
    "\n",
    "def get_state_population(state_name, population_input_file):\n",
    "    df = pd.read_csv(population_input_file)\n",
    "    filtered_df = df[df['name'] == state_name]\n",
    "    if len(filtered_df) > 0:\n",
    "        population = filtered_df['population'].values[0]\n",
    "        return population\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_city_population(city_name,population_input_file):\n",
    "    country_code = 'ML'\n",
    "    url = \"https://wft-geo-db.p.rapidapi.com/v1/geo/cities/{0}\".format(get_wikidata_id(city_name))\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"6e1b07b54fmsh14df87e58d9db7bp175272jsn85fd0398365f\",\n",
    "        \"X-RapidAPI-Host\": \"wft-geo-db.p.rapidapi.com\"\n",
    "    }\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "    if response.status_code == 404:\n",
    "        get_state_population(city_name,population_input_file)\n",
    "\n",
    "    else:\n",
    "        data = response.json()\n",
    "        population = data[\"data\"]['population']\n",
    "        return population\n",
    "    \n",
    "def filter_table(df, colname, adminlevel):\n",
    "    if adminlevel == \"admin1\":\n",
    "        adminlist = df.admin1.unique()\n",
    "    elif adminlevel == \"location\":\n",
    "        adminlist = df.location.unique()\n",
    "    else:\n",
    "        adminlist = df.admin2.unique()\n",
    "\n",
    "    newdf = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "\n",
    "    for admin in adminlist:\n",
    "        tempdf = df.loc[df[adminlevel] == admin]\n",
    "        tempdf.sort_values(colname, ascending=True)\n",
    "        newdf = pd.concat([newdf, tempdf.tail(1)])\n",
    "\n",
    "    return newdf\n",
    "\n",
    "\n",
    "\n",
    "def acled2locations(country, start_date, filter_opt, admin_level):\n",
    "    current_dir = os.getcwd()\n",
    "    input_file = os.path.join(current_dir, country, \"acled.csv\") \n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "    except:\n",
    "        print(\"Runtime Error: File Cannot be found\")\n",
    "        return\n",
    "    \n",
    "    df = df[[\"event_date\", \"country\", \"admin1\", \"latitude\", \"longitude\", \"fatalities\"]]\n",
    "    \n",
    "    event_dates = df[\"event_date\"].tolist()\n",
    "    \n",
    "    formatted_event_dates = [date_format(date) for date in event_dates]\n",
    "    \n",
    "    conflict_dates = [between_date(d, start_date) for d in formatted_event_dates]\n",
    "    \n",
    "    df['conflict_date'] = conflict_dates\n",
    "    \n",
    "    fatalities_threshold = 0\n",
    "    \n",
    "    df = drop_rows(df, 'fatalities', fatalities_threshold)\n",
    "    df = df.sort_values([\"conflict_date\", \"admin1\"]).drop_duplicates([\"conflict_date\", \"admin1\"])\n",
    "    \n",
    "    if filter_opt == 'earliest':\n",
    "        filter_opt = 'conflict_date'\n",
    "\n",
    "    try:\n",
    "        df = filter_table(df, filter_opt, admin_level)\n",
    "    except:\n",
    "        print(\"Runtime error: filter_opt value must be earliest or fatalities\")\n",
    "        \n",
    "    output_df = df[['admin1', 'country', 'latitude', 'longitude', 'conflict_date']]\n",
    "    output_df.columns = ['name', 'country', 'latitude', 'longitude', 'conflict_date']\n",
    "    \n",
    "    output_df.loc[:, \"location_type\"] = \"conflict_zone\"\n",
    "    \n",
    "    population = [get_state_population(name, population_input_file) for name in df['admin1']]\n",
    "    \n",
    "    output_df['population'] = population\n",
    "    \n",
    "    output_df['population'] = output_df['population'].replace([np.inf, -np.inf, np.nan], 0)\n",
    "    output_df['population'] = output_df['population'].astype(int)  # Convert population to integers\n",
    "    \n",
    "    output_df = output_df[['name', 'country', 'latitude', 'longitude', 'location_type', 'conflict_date', 'population']]\n",
    "    output_file = os.path.join(country, \"locations.csv\")\n",
    "    \n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    print(\"locations.csv file is created. Please inspect the file for zero population.\")\n",
    "    print(\"Location names from locations.csv must match the population.csv locations.\")\n",
    "\n",
    "    \n",
    "# Set the values for country, start_date, filter_opt, adminlevel, and population_input_file\n",
    "country = \"syria\"\n",
    "start_date = \"01-09-2022\"\n",
    "filter_opt = 'earliest'\n",
    "adminlevel = \"admin1\"\n",
    "population_input_file = os.path.join(country, \"population.csv\")\n",
    "\n",
    "acled2locations(country, start_date, filter_opt, adminlevel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a35aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 9\n",
    "\n",
    "# Converts locations.csv to conflicts.csv\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# Replace '/path/to/InputGeography' with the actual directory path\n",
    "sys.path.append('/home/mghorbani/workspace/FabSim/flee/flee')  \n",
    "\n",
    "from InputGeography import InputGeography\n",
    "\n",
    "def find_column_index(header, column_name):\n",
    "    # Find the index of a column by matching its name in the header\n",
    "    for i, col in enumerate(header):\n",
    "        if col == column_name:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def location2conflict(simulation_period, input_file, output_file):\n",
    "    ig = InputGeography()\n",
    "    ig.ReadLocationsFromCSV(input_file)\n",
    "\n",
    "    with open(input_file, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)\n",
    "        conflict_zone_index = find_column_index(header, \"location_type\")\n",
    "        conflict_date_index = find_column_index(header, \"conflict_date\")\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        output_header_string = \"day\"\n",
    "        for l in ig.locations:\n",
    "            output_header_string += \",%s\" % l[0]\n",
    "        output_header_string += \"\\n\"\n",
    "        file.write(output_header_string)\n",
    "\n",
    "        for t in range(0, simulation_period):\n",
    "            output = \"%s\" % t\n",
    "            for l in ig.locations:\n",
    "                if l[conflict_zone_index] == \"conflict_zone\":\n",
    "                    confl_date = int(l[conflict_date_index])\n",
    "                    if confl_date <= t:\n",
    "                        output += \",1\"\n",
    "                    else:\n",
    "                        output += \",0\"\n",
    "                else:\n",
    "                    output += \",0\"\n",
    "            output += \"\\n\"\n",
    "            file.write(output)\n",
    "\n",
    "\n",
    "# Set the values for simulation_period, input_file, and output_file\n",
    "simulation_period = 272\n",
    "\n",
    "# Please specify a country name\n",
    "country = \"syria\"\n",
    "\n",
    "input_file = os.path.join(country, \"locations.csv\")\n",
    "\n",
    "output_file = os.path.join(country, \"conflicts.csv\")\n",
    "\n",
    "# Call the function location2conflict\n",
    "location2conflict(simulation_period, input_file, output_file)\n",
    "\n",
    "print(\"conflicts.csv file is created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 10\n",
    "\n",
    "# Extends mdified-conflicts.csv based on conflicts.csv\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "\n",
    "def read_conflict_zones(filename):\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        conflict_zones = df.columns[1:].tolist()\n",
    "        conflict_zones = [zone for zone in conflict_zones if zone]  # Exclude empty headers\n",
    "        return conflict_zones\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found: \", filename)\n",
    "        return []\n",
    "    \n",
    "    \n",
    "# Custom function to generate all zeros csv file\n",
    "def generate_conflict_zones_csv(filename, conflict_zones, period):\n",
    "    data = {'#Days': list(range(period))}\n",
    "    data.update({zone: [0] * period for zone in conflict_zones})\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "\n",
    "# Custom distribution function 1\n",
    "def custom_distribution1(intensity, x):\n",
    "    max_value = intensity\n",
    "    peak_day = 400\n",
    "    std_deviation = 130\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factor = np.exp(-((x - peak_day) / std_deviation) ** 2)\n",
    "    \n",
    "    # Add random fluctuations to the spreading factor\n",
    "    spreading_factor += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    y = max_value * spreading_factor\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 2\n",
    "def custom_distribution2(intensity, x):\n",
    "    peak_day = 100\n",
    "    max_value = intensity\n",
    "    std_deviation = 100\n",
    "    rise_factor = 1.5\n",
    "    fall_factor = 0.125\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factor_rising = np.exp(-((x - peak_day) / std_deviation) ** 2) ** rise_factor\n",
    "    spreading_factor_falling = np.exp(-((x - peak_day) / (std_deviation * 2)) ** 2) ** fall_factor\n",
    "    \n",
    "    # Add random fluctuations to the spreading factors\n",
    "    spreading_factor_rising += np.random.normal(0, variation_factor, len(x))\n",
    "    spreading_factor_falling += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    y_rising = max_value * spreading_factor_rising\n",
    "    y_falling = max_value * spreading_factor_falling\n",
    "    y = np.where(x < peak_day, y_rising, y_falling)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 3\n",
    "def custom_distribution3(intensity, x):\n",
    "    peak1_day = 300\n",
    "    peak2_day = 600\n",
    "    max_value = intensity\n",
    "    std_deviation1 = 30\n",
    "    std_deviation2 = 50\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factor1 = np.exp(-((x - peak1_day) / std_deviation1) ** 2)\n",
    "    spreading_factor2 = np.exp(-((x - peak2_day) / std_deviation2) ** 2)\n",
    "    \n",
    "    # Add random fluctuations to the spreading factors\n",
    "    spreading_factor1 += np.random.normal(0, variation_factor, len(x))\n",
    "    spreading_factor2 += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    y = max_value * (spreading_factor1 + spreading_factor2)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 4\n",
    "def custom_distribution4(intensity, x):\n",
    "    peak1_day = 150\n",
    "    peak2_day = 650\n",
    "    max_value = intensity\n",
    "    std_deviation1 = 30\n",
    "    std_deviation2 = 50\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factor1 = np.exp(-((x - peak1_day) / std_deviation1) ** 2)\n",
    "    spreading_factor2 = np.exp(-((x - peak2_day) / std_deviation2) ** 2)\n",
    "    \n",
    "    # Add random fluctuations to the spreading factors\n",
    "    spreading_factor1 += np.random.normal(0, variation_factor, len(x))\n",
    "    spreading_factor2 += np.random.normal(0, variation_factor, len(x))\n",
    "    \n",
    "    y = max_value * (spreading_factor1 + spreading_factor2)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 5\n",
    "def custom_distribution5(intensity, x):\n",
    "    peaks = [100, 200, 300, 400, 500]  # Adjust the peak days as desired\n",
    "    max_value = intensity\n",
    "    std_deviations = [10, 10, 10, 10, 10]  # Adjust the standard deviations as desired\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factors = []\n",
    "    for peak, std_deviation in zip(peaks, std_deviations):\n",
    "        spreading_factor = np.exp(-((x - peak) / std_deviation) ** 2)\n",
    "        spreading_factor += np.random.normal(0, variation_factor, len(x))\n",
    "        spreading_factors.append(spreading_factor)\n",
    "    \n",
    "    y = max_value * sum(spreading_factors)\n",
    "    return y\n",
    "\n",
    "# Custom distribution function 6\n",
    "def custom_distribution6(intensity, x):\n",
    "    peaks = [300, 400, 500, 650]  # Adjust the peak days as desired\n",
    "    hill_width = 20  # Adjust the width of the hill\n",
    "    max_value = intensity\n",
    "    std_deviations = [10, 20, 30, 40]  # Adjust the standard deviations as desired\n",
    "    variation_factor = 0.1  # Adjust the variation factor as desired\n",
    "    \n",
    "    spreading_factors = []\n",
    "    for peak, std_deviation in zip(peaks, std_deviations):\n",
    "        spreading_factor = np.exp(-((x - peak) / std_deviation) ** 2)\n",
    "        \n",
    "        # Create the hill shape by adding a flat plateau around the peak\n",
    "        hill_mask = np.logical_and(x >= peak - hill_width, x <= peak + hill_width)\n",
    "        spreading_factor[hill_mask] = max_value\n",
    "        \n",
    "        spreading_factor += np.random.normal(0, variation_factor, len(x))\n",
    "        spreading_factors.append(spreading_factor)\n",
    "    \n",
    "    y = max_value * sum(spreading_factors)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Custom distribution function 7\n",
    "def custom_distribution7(intensity, x):\n",
    "    period = 365  # Length of one complete period (in days)\n",
    "    max_value = intensity  # Maximum value for conflict intensity\n",
    "    variation_factor = 0.5  # Adjust the variation factor as desired\n",
    "    \n",
    "    # Compute the phase angle based on the day of the year\n",
    "    phase_angle = (x % period) / period * 2 * np.pi\n",
    "    \n",
    "    # Use a sine function to model the seasonal variation\n",
    "    y = max_value * np.sin(phase_angle)\n",
    "    \n",
    "    # Add random noise with the specified variation factor\n",
    "    y += np.random.normal(0, variation_factor, len(x))\n",
    "    y = abs(y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "# Specify the simulation country\n",
    "country = 'syria'\n",
    "\n",
    "# Create the path to input file\n",
    "input_file = os.path.join(country, 'conflicts.csv')\n",
    "\n",
    "# Call the function to extract the conflict_zones from the file\n",
    "conflict_zones = read_conflict_zones(input_file)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Specify the simulation period\n",
    "period = 732\n",
    "\n",
    "# Generate x-axis values from 0 to 731\n",
    "start_date = date(2022, 9, 1)\n",
    "current_date = date(2023, 5, 31)\n",
    "days_passed = (current_date - start_date).days\n",
    "\n",
    "# Generate x-axis values using custom_distribution1 and custom_distribution2\n",
    "x1 = np.linspace(0, days_passed, num=days_passed).astype(int)\n",
    "x2 = np.linspace(days_passed, period, num=period - days_passed).astype(int)\n",
    "\n",
    "# Generate y-axis values using conflicts values\n",
    "y1 = df.iloc[:, 1:days_passed + 1].sum(axis=1)[:days_passed]\n",
    "\n",
    "# Set the intensity as maximum number of conflict zones \n",
    "intensity = 13\n",
    "\n",
    "# Generate y-axis values using custom_distribution2\n",
    "y2 = custom_distribution1(intensity, x2)\n",
    "\n",
    "# Combine the generated data\n",
    "x = np.concatenate((x1, x2))\n",
    "y = np.concatenate((y1, y2))\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# Plot graph\n",
    "ax1.plot(x, y)\n",
    "ax1.set_title('Custom Distribution')\n",
    "ax1.set_xlabel('Days')\n",
    "ax1.set_ylabel('Conflict Zones')\n",
    "\n",
    "# Convert y values to integers\n",
    "y = [int(val) for val in y]\n",
    "\n",
    "# Create path to modified CSV file\n",
    "output_file = os.path.join(country, \"modified-conflicts.csv\")\n",
    "\n",
    "# Call the function to generate all zeros csv file\n",
    "generate_conflict_zones_csv(output_file, conflict_zones, period)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_modified = pd.read_csv(output_file)\n",
    "\n",
    "# Update the modified DataFrame with the new y values\n",
    "modified_rows = []\n",
    "y_index = 0\n",
    "for _, row in df_modified.iterrows():\n",
    "    row = row.values\n",
    "    if y_index >= len(y):\n",
    "        break\n",
    "\n",
    "    number = y[y_index]\n",
    "    y_index += 1\n",
    "    assigned_count = 0\n",
    "    for i in range(1, len(row)):\n",
    "        if assigned_count < number:\n",
    "            row[i] = 1\n",
    "            assigned_count += 1\n",
    "        else:\n",
    "            row[i] = 0\n",
    "\n",
    "    modified_rows.append(row)\n",
    "    \n",
    "# Create modified DataFrame\n",
    "modified_df = pd.DataFrame(modified_rows, columns=df.columns)\n",
    "\n",
    "# Compute the sum of each row (excluding the '#Day' column)\n",
    "sum_values = modified_df.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Plot the summed values\n",
    "ax2.plot(x, sum_values)\n",
    "ax2.set_title('modified-conflicts.csv')\n",
    "ax2.set_xlabel('Days')\n",
    "\n",
    "# Save the modified DataFrame to the output file\n",
    "modified_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b8031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 11\n",
    "\n",
    "# Creates routes.csv from locations.csv\n",
    "\n",
    "import webbrowser\n",
    "import folium\n",
    "import requests\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import polyline\n",
    "import csv\n",
    "\n",
    "\n",
    "# Function to decode a polyline string into a list of locations\n",
    "def decode_polyline(polyline_str):\n",
    "    return polyline.decode(polyline_str)\n",
    "\n",
    "\n",
    "country = 'syria'\n",
    "\n",
    "# Read the locations from the CSV file\n",
    "df = pd.read_csv('{}/locations.csv'.format(country))\n",
    "\n",
    "# Create layers for location markers and routes\n",
    "layer1 = folium.FeatureGroup(name='Locations')\n",
    "layer2 = folium.FeatureGroup(name='Routes')\n",
    "\n",
    "# Initialize the map\n",
    "map_center = (df['latitude'].mean(), df['longitude'].mean())\n",
    "m = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# Create markers for conflict zones, towns, and camps within the distance threshold\n",
    "conflict_zones = []\n",
    "towns = []\n",
    "camps = []\n",
    "distance_threshold = 1000  # Set the distance threshold in kilometers\n",
    "locations_not_found = []  # List to store locations not found within the threshold\n",
    "for index, row in df.iterrows():\n",
    "    location = [row['latitude'], row['longitude']]\n",
    "    if row['location_type'] == 'conflict_zone':\n",
    "        conflict_zones.append({'location': location, 'name': row['name']})\n",
    "        if any(geodesic(location, cz['location']).km <= distance_threshold for cz in conflict_zones):\n",
    "            layer1.add_child(folium.CircleMarker(location=tuple(location), radius=6, color='red', fill=True, fill_color='red',\n",
    "                                                 popup=row['name']))\n",
    "        else:\n",
    "            locations_not_found.append(row['name'])\n",
    "    elif row['location_type'] == 'town':\n",
    "        towns.append({'location': location, 'name': row['name']})\n",
    "        if any(geodesic(location, t['location']).km <= distance_threshold for t in towns):\n",
    "            layer1.add_child(folium.CircleMarker(location=tuple(location), radius=6, color='orange', fill=True, fill_color='orange',\n",
    "                                                 popup=row['name']))\n",
    "        else:\n",
    "            locations_not_found.append(row['name'])\n",
    "    elif row['location_type'] == 'camp':\n",
    "        camps.append({'location': location, 'name': row['name']})\n",
    "        if any(geodesic(location, c['location']).km <= distance_threshold for c in camps):\n",
    "            layer1.add_child(folium.CircleMarker(location=tuple(location), radius=6, color='green', fill=True, fill_color='green',\n",
    "                                                 popup=row['name']))\n",
    "        else:\n",
    "            locations_not_found.append(row['name'])\n",
    "\n",
    "# Create markers for locations not found within the threshold\n",
    "for location_name in locations_not_found:\n",
    "    print(f\"Location not found within the threshold: {location_name}\")\n",
    "    \n",
    "routes = []\n",
    "# Connect all locations using Google Maps Directions API\n",
    "for loc1 in df.itertuples():\n",
    "    loc1_type = loc1.location_type\n",
    "    loc1_coords = (loc1.latitude, loc1.longitude)\n",
    "\n",
    "    for loc2 in df.itertuples():\n",
    "        loc2_type = loc2.location_type\n",
    "        loc2_coords = (loc2.latitude, loc2.longitude)\n",
    "\n",
    "        if loc1 != loc2:\n",
    "            # Calculate the distance between loc1_coords and loc2_coords\n",
    "            distance = geodesic(loc1_coords, loc2_coords).km\n",
    "\n",
    "            # Limit the search to locations within a certain distance threshold\n",
    "            if distance <= 1000:  # Adjust the distance threshold as needed\n",
    "                # Use Google Maps Directions API to obtain the route\n",
    "                api_url = \"https://maps.googleapis.com/maps/api/directions/json\"\n",
    "                params = {\n",
    "                    \"origin\": f\"{loc1_coords[0]},{loc1_coords[1]}\",\n",
    "                    \"destination\": f\"{loc2_coords[0]},{loc2_coords[1]}\",\n",
    "                    \"key\": \"\" # Replace with your own Google Maps API key\n",
    "                }\n",
    "                response = requests.get(api_url, params=params)\n",
    "                data = response.json()\n",
    "\n",
    "                # Extract the polyline representing the route\n",
    "                if data[\"status\"] == \"OK\":\n",
    "                    polyline_points = data[\"routes\"][0][\"overview_polyline\"][\"points\"]\n",
    "                    polyline_locations = decode_polyline(polyline_points)\n",
    "\n",
    "                    # Create a route with the polyline locations\n",
    "                    if loc1_type == 'town' or loc2_type == 'town':\n",
    "                        color = 'purple'  # Set color for routes involving towns\n",
    "                    elif loc1_type != loc2_type:\n",
    "                        color = 'green'  # Set color for routes between different location types\n",
    "                    else:\n",
    "                        color = 'blue'  # Set color for routes between the same location types\n",
    "                    layer2.add_child(folium.PolyLine(locations=polyline_locations, color=color, weight=2.5))\n",
    "\n",
    "                    # Append the route information to the routes list\n",
    "                    forced_redirection = int(loc1_type != loc2_type and loc1_type != 'town' and loc2_type != 'town')\n",
    "                    routes.append([loc1.name, loc2.name, distance, forced_redirection])\n",
    "                else:\n",
    "                    print(f\"No route found between {loc1.name} and {loc2.name}\")\n",
    "\n",
    "\n",
    "# Save the routes to a CSV file\n",
    "output_file = '{}/routes.csv'.format(country)\n",
    "with open(output_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"name1\", \"name2\", \"distance\", \"forced_redirection\"])\n",
    "    writer.writerows(routes)\n",
    "\n",
    "# Add the layers to the map\n",
    "m.add_child(layer2)\n",
    "m.add_child(layer1)\n",
    "\n",
    "# Add the layer control to the map\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Save map in html\n",
    "m.save('{}/map.html'.format(country))\n",
    "\n",
    "# Display map in browser\n",
    "#webbrowser.open('{}/map.html'.format(country))\n",
    "\n",
    "# Display map in here\n",
    "m\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
